# ────────────────────────────────────────────────────────────────
#  Codex + SWE-bench Self-Improving Pipeline
#  • Edits code with Codex (Full-Auto, driven by AGENTS.md)
#  • Generates patches for remaining SWE-bench-Lite failures
#    using GPT-4.1-mini via SWE-agent (only git_apply_patch)
#  • Evaluates with SWE-bench harness
#  • Updates AGENTS.md based on failures
#  • Commits code, predictions, results, and refined AGENTS.md
# ────────────────────────────────────────────────────────────────
name: Codex Self-Improving Pipeline

on:
  workflow_dispatch:
  # schedule:
  #   - cron: '0 1 * * *'          # uncomment for daily 01:00 UTC runs

env:
  MODEL_NAME: gpt-4.1-mini        # model for SWE-agent

jobs:
  # ────────────────────────────────────────────────────────────────
  # 1) Let Codex edit the repo according to the *current* AGENTS.md
  # ────────────────────────────────────────────────────────────────
  codex-auto-update:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.G_TOKEN }}

      - name: Set up Node.js 22 (Codex CLI requirement)
        uses: actions/setup-node@v4
        with:
          node-version: '22'

      - name: Install Codex CLI globally
        run: npm install -g @openai/codex

      - name: Run Codex CLI in Full-Auto mode (AGENTS.md)
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          CODEX_QUIET_MODE: "1"
        run: |
          codex --approval-mode full-auto --quiet \
            "follow the instructions in AGENTS.md"

  # ────────────────────────────────────────────────────────────────
  # 2) Evaluate, generate new patches, and refine AGENTS.md
  # ────────────────────────────────────────────────────────────────
  swebench-eval:
    needs: codex-auto-update
    runs-on: ubuntu-latest

    steps:
      # 2-1 Repo state *after* Codex edits
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.G_TOKEN }}

      # 2-2 Python
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      # 2-3 Install SWE-bench harness + SWE-agent (editable clone ⇒ includes folders)
      - name: Install SWE-bench & SWE-agent (editable)
        run: |
          pip install --upgrade pip
          pip install git+https://github.com/SWE-bench/SWE-bench.git@main
          git clone --depth 1 https://github.com/SWE-agent/SWE-agent.git
          pip install -e SWE-agent            # keeps config/, tools/, trajectories/

      # 2-4 Identify still-failing instances (if any)
      - name: Get list of previously failed instances
        id: failcheck
        run: |
          python scripts/get_failed_instances.py \
            evaluation_results/latest/instance_results.jsonl \
            failed_instances.txt || true
          if [ -s failed_instances.txt ]; then
            echo "slice_arg=--instances.file failed_instances.txt" >> $GITHUB_OUTPUT
            echo "::notice::Running only failing instances"
          else
            echo "slice_arg=" >> $GITHUB_OUTPUT
            echo "::notice::No previous results – running full Lite split"
          fi

      # 2-5 Generate new patches with SWE-agent (only git_apply_patch)
      - name: Generate GPT-4.1-mini patches (SWE-agent)
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        run: |
          sweagent run-batch \
            --agent.model.name $MODEL_NAME \
            --agent.tools.allow git_apply_patch \
            --agent.tools.parse_function.type thought_action \
            --instances.type swe_bench \
            --instances.subset lite \
            --instances.split dev \
            ${{ steps.failcheck.outputs.slice_arg }} \
            --num_workers 4 \
            --output_dir sweagent_output

      # 2-6 Convert preds.json → JSONL
      - name: Convert preds.json to JSONL
        run: |
          python scripts/jsonl_from_preds.py \
            sweagent_output/preds.json predictions_NEW.jsonl

      # 2-7 Merge with existing best-known predictions
      - name: Merge predictions
        run: |
          python scripts/merge_predictions.py \
            predictions_NEW.jsonl predictions.jsonl

      # 2-8 Evaluate merged predictions with SWE-bench harness
      - name: Run SWE-bench evaluation
        run: |
          python -m swebench.harness.run_evaluation \
            --dataset_name princeton-nlp/SWE-bench_Lite \
            --predictions_path predictions.jsonl \
            --max_workers 8 \
            --run_id codex_${{ github.run_number }}

      # 2-9 Create a prompt for Codex to refine AGENTS.md
      - name: Build AGENTS.md update prompt
        run: |
          python scripts/build_agents_prompt.py \
            evaluation_results/latest/instance_results.jsonl \
            agents_update_prompt.txt

      # 2-10 Call Codex to update AGENTS.md in place
      - name: Self-update AGENTS.md with Codex
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        run: |
          codex --approval-mode full-auto --quiet "$(cat agents_update_prompt.txt)"

      # 2-11 Update “latest” symlink for next run
      - name: Move latest symlink
        run: |
          rm -rf evaluation_results/latest || true
          ln -s $(ls -d evaluation_results/codex_* | sort | tail -n1) \
                evaluation_results/latest

      # 2-12 Commit and push everything back
      - name: Commit and push changes
        env:
          G_TOKEN: ${{ secrets.G_TOKEN }}
        run: |
          git config user.name  "codex-bot"
          git config user.email "codex-bot@users.noreply.github.com"
          git add -A
          if [ -n "$(git status --porcelain)" ]; then
            git commit -m "Codex self-improving run: code + results + AGENTS.md"
            git remote set-url origin https://x-access-token:${G_TOKEN}@github.com/${{ github.repository }}.git
            git push origin HEAD:${GITHUB_REF#refs/heads/}
          fi
